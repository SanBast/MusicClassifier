{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Final_mood.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"D1jtRF-YdZTa"},"source":["#Load libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TEob_QLFEgE","executionInfo":{"status":"ok","timestamp":1629097812401,"user_tz":-120,"elapsed":36116,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"f6173d02-4df6-4875-93e5-e140832d6bd8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZKq65BeAFWh1","executionInfo":{"status":"ok","timestamp":1629097818447,"user_tz":-120,"elapsed":4557,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"9a97628b-a5e5-4cdb-bdee-2f2cbd8e1927"},"source":["!pip install torchaudio\n","!pip install pydub\n","!pip install spotipy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torchaudio\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n","Installing collected packages: torchaudio\n","Successfully installed torchaudio-0.9.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qdR-XWXzkBTZ"},"source":["import torch\n","from torch import nn\n","from torch._C import device\n","from torch.nn.modules.activation import ReLU\n","from torch.nn.modules.linear import Linear\n","from torch.utils import data\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import datasets\n","import torchvision\n","from sklearn import preprocessing\n","from torch import Tensor\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix, classification_report\n","from torchvision.transforms import ToTensor\n","from sklearn.model_selection import train_test_split\n","import torchaudio as ta\n","import librosa\n","import numpy as np\n","import scipy\n","from scipy import misc\n","import glob\n","import random\n","from PIL import Image\n","import os\n","from pydub import AudioSegment\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n","from collections import Counter\n","import shutil\n","from urllib.request import urlretrieve\n","from spotipy.oauth2 import SpotifyClientCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F5ktyZjsdeZb"},"source":["## Checking GPU availability"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWIa4zEtFnib","executionInfo":{"status":"ok","timestamp":1629097833348,"user_tz":-120,"elapsed":8,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"954bfda7-40be-40f1-8520-f9a489db2680"},"source":["if torch.cuda.is_available():\n","    device = \"cuda\"\n","else:\n","    device = \"cpu\"\n","print(f\"Using {device} device\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using cuda device\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I5z5KLr-eaFb"},"source":["## Create Spotify Dataset"]},{"cell_type":"code","metadata":{"id":"tgoSyBxjFpTD"},"source":["def spotify_login(cid, secret):\n","    client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret) \n","    return spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n","\n","cid = \"User_ID\"\n","secret = \"Secret_PWD\"\n","\n","spotify = spotify_login(cid, secret)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YzyVjYXXZA_F"},"source":["playlists = {'Happy' : [\"37i9dQZF1DXdPec7aLTmlC\", \"1h90L3LP8kAJ7KGjCV2Xfd\"],\n","             'Sad' : [\"37i9dQZF1DX7qK8ma5wgG1\", \"4kPr5JnmXhy9OxewtmylVI\"],\n","             'Energetic' : [\"2lmcuXNkjYOoQeXvwqvvFT\", \"37i9dQZF1DWT6anPZiHuxz\"],\n","             'Dark' : [\"37i9dQZF1DX2pSTOxoPbx9\", \"4Nv06dxNVcYcL88w8WbZVY\"],\n","             'Relaxing' : [\"37i9dQZF1DWTC99MCpbjP8\", \"7jM62qbx0nLl82afAgU3kb\"]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-U7uVlfb46x"},"source":["def write_songs(spotify, directory, id, mood):\n","  playlist_tracks = spotify.playlist_tracks(id)\n","  preview_urls = []\n","  counter = 0\n","  for track in playlist_tracks['items']:\n","    try:\n","      if track['track']['preview_url'] is None:\n","        counter = counter + 1\n","        continue\n","      preview_urls.append(track['track']['preview_url'])\n","    except:\n","      counter = counter + 1\n","      continue\n","  for i in range(len(preview_urls)):\n","    urlretrieve(preview_urls[i], \"{}/{}{}{}\".format(directory, mood, i+1, \".mp3\"))\n","  print(f\"number of skipped song in current playlist: {counter}\")\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_AM6h7vFbFbe"},"source":["def get_songs(spotify, playlists, directory):\n","  for mood, ids in playlists.items():\n","      print(mood)\n","      for id in ids:\n","          write_songs(spotify, directory + \"/\" + mood, id, mood)\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHYjRdjPaRjO","outputId":"75de90b4-0ef1-4482-b400-3969b11b89da"},"source":["get_songs(spotify, playlists, \"/content/drive/MyDrive/Colab Notebooks/music_project/team_project/Spotify\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Happy\n","number of skipped song in current playlist: 37\n","number of skipped song in current playlist: 3\n","Sad\n","number of skipped song in current playlist: 25\n","number of skipped song in current playlist: 48\n","Energetic\n","number of skipped song in current playlist: 51\n","number of skipped song in current playlist: 9\n","Dark\n","number of skipped song in current playlist: 34\n","number of skipped song in current playlist: 10\n","Relaxing\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UU9y3HRcXfwT"},"source":["moods = 'Dark Energetic Happy Relaxing Sad'\n","moods = moods.split()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5uHMRcRO00Xf"},"source":["## Building Folders\n"]},{"cell_type":"code","metadata":{"id":"uTi-YMve2ixj"},"source":["os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio3sec')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio5sec')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio10sec')\n","\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio3sec/train')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio3sec/test')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio3sec/val')\n","\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio5sec/train')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio5sec/test')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio5sec/val')\n","\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio10sec/train')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio10sec/test')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio10sec/val')\n","\n","'''os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/test')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/train')\n","os.makedirs('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/val')'''\n","\n","for m in moods:\n","\n","  path_train = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio3sec/train',f'{m}')\n","  path_test = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio3sec/test',f'{m}')\n","  path_val = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio3sec/val',f'{m}')\n","  os. makedirs(path_train)\n","  os. makedirs(path_test)\n","  os. makedirs(path_val)\n","\n","  path_train = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio5sec/train',f'{m}')\n","  path_test = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio5sec/test',f'{m}')\n","  path_val = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio5sec/val',f'{m}')\n","  os. makedirs(path_train)\n","  os. makedirs(path_test)\n","  os. makedirs(path_val)\n","\n","  path_train = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio10sec/train',f'{m}')\n","  path_test = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio10sec/test',f'{m}')\n","  path_val = os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio10sec/val',f'{m}')\n","  os. makedirs(path_train)\n","  os. makedirs(path_test)\n","  os. makedirs(path_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tRR5hriTUH_L"},"source":["##Creating Train/Test/Val Set and Mel-Spectrograms"]},{"cell_type":"code","metadata":{"id":"e-afJDl0YplH"},"source":["#select the segmentation window (1, 3, 5, 10) seconds\n","segment = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A43g4rhkRjSi","executionInfo":{"status":"ok","timestamp":1631284105108,"user_tz":-120,"elapsed":1764562,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"f7593fb8-9e45-4e95-cf4a-c99c1aedb825"},"source":["directory = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/Spotify'\n","\n","i=0\n","for m in moods:\n","  print(m)\n","  j=0\n","  \n","  filenames = os.listdir(os.path.join(directory,f\"{m}\"))\n","\n","  train_files, test_files = train_test_split(filenames, test_size=0.1, random_state=42)\n","  test_files, val_file = train_test_split(test_files, test_size=0.2, random_state=42)\n","  for f in test_files:\n","    j = j+1\n","    song  =  os.path.join(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/Spotify/{m}',f'{f}')\n","    for w in range(0,30//segment):\n","      i = i+1\n","      t1 = segment*(w)*1000\n","      t2 = segment*(w+1)*1000\n","      path = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio'+str(segment)+'sec/test/'+m+'/'+f+'_'+str(j)+str(w)+'.mp3'\n","      newAudio = AudioSegment.from_mp3(song)\n","      new = newAudio[t1:t2]\n","      new.export(path, format=\"mp3\")\n","\n","  i=0\n","  j=0\n","  for f in train_files:\n","    j = j+1\n","    song  =  os.path.join(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/Spotify/{m}',f'{f}')\n","    for w in range(0,30//segment):\n","      i = i+1\n","      t1 = segment*(w)*1000\n","      t2 = segment*(w+1)*1000\n","      path = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio'+str(segment)+'sec/train/'+m+'/'+f+'_'+str(j)+str(w)+'.mp3'\n","      newAudio = AudioSegment.from_mp3(song)\n","      new = newAudio[t1:t2]\n","      new.export(path, format=\"mp3\")\n","\n","  i=0\n","  j=0\n","  for f in val_file:\n","    j+=1\n","    song  =  os.path.join(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/Spotify/{m}',f'{f}')\n","    for w in range(0,30//segment):\n","        i = i+1\n","        t1 = segment*(w)*1000\n","        t2 = segment*(w+1)*1000\n","        path = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio'+str(segment)+'sec/val/'+m+'/'+f+'_'+str(j)+str(w)+'.mp3'\n","        newAudio = AudioSegment.from_mp3(song)\n","        new = newAudio[t1:t2]\n","        new.export(path, format=\"mp3\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dark\n","54 4 2\n","Dark9.mp3 Dark31.mp3 Dark35.mp3\n","Energetic\n","44 4 1\n","Energetic21.mp3 Energetic12.mp3 Energetic40.mp3\n","Happy\n","87 8 2\n","Happy77.mp3 Happy45.mp3 Happy47.mp3\n","Relaxing\n","79 7 2\n","Relaxing17.mp3 Relaxing16.mp3 Relaxing55.mp3\n","Sad\n","46 4 2\n","Sad18.mp3 Sad6.mp3 Sad20.mp3\n"]}]},{"cell_type":"markdown","metadata":{"id":"LlOdVzIoUb0f"},"source":["### TRAIN SPLIT"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MR1030465JHL","executionInfo":{"status":"ok","timestamp":1631284190387,"user_tz":-120,"elapsed":85304,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"0de7b294-8af3-4cc9-eb76-6b911e5357f5"},"source":["X_train = []\n","Y_train = []\n","X_train_songs = []\n","\n","sr = 22050\n","hop_length = 512\n","n_fft = 2048\n","\n","for m in moods:\n","  j = 0\n","  print(m)\n","  for filename in os.listdir(os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio'+str(segment)+'sec/train',f\"{m}\")):\n","    song  =  os.path.join(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio{segment}sec/train/{m}',f'{filename}')\n","    j = j+1\n","    \n","    y, sr = ta.load(song)\n","    S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","    log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    Y_train.append(m)\n","    X_train.append(log_S.to(device))\n","    fields = song.split('/')\n","    song_name = str(song.split('.')[0])\n","    X_train_songs.append(song_name)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dark\n","Energetic\n","Happy\n","Relaxing\n","Sad\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bw_wmeaDKf-n","executionInfo":{"status":"ok","timestamp":1631284190389,"user_tz":-120,"elapsed":7,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"56d0a8b6-ecea-4b9b-bd73-596494675660"},"source":["len(X_train), len(X_train_songs)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3100, 3100)"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"WbVuWJzsUi3t"},"source":["### TEST SPLIT"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzGGHcriUhHP","executionInfo":{"status":"ok","timestamp":1631284197358,"user_tz":-120,"elapsed":6974,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"bdbffd29-87b4-4045-e923-fc9933d2418a"},"source":["X_test = []\n","X_test_songs = []\n","Y_test = []\n","\n","sr = 22050\n","hop_length = 512\n","n_fft = 2048\n","\n","for m in moods:\n","  j = 0\n","  print(m)\n","  for filename in os.listdir(os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio'+str(segment)+'sec/test',f\"{m}\")):\n","    song  =  os.path.join(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio{segment}sec/test/{m}',f'{filename}')\n","    j = j+1\n","    \n","    y, sr = ta.load(song)\n","    S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","    log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    Y_test.append(m)\n","    X_test.append(log_S.to(device))\n","\n","    fields = song.split('/')\n","    song_name = str(song.split('.')[0])\n","    X_test_songs.append(song_name)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dark\n","Energetic\n","Happy\n","Relaxing\n","Sad\n"]}]},{"cell_type":"markdown","metadata":{"id":"0Ipryf8dUvMe"},"source":["### VAL SPLIT"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MkWSi-xUhV1","executionInfo":{"status":"ok","timestamp":1631284199594,"user_tz":-120,"elapsed":2242,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"2a06f553-1abb-41ea-853b-b8999184d485"},"source":["X_val = []\n","X_val_songs = []\n","Y_val = []\n","\n","sr = 22050\n","hop_length = 512\n","n_fft = 2048\n","\n","for m in moods:\n","  j = 0\n","  print(m)\n","  for filename in os.listdir(os.path.join('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio'+str(segment)+'sec/val',f\"{m}\")):\n","    song  =  os.path.join(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood/audio{segment}sec/val/{m}',f'{filename}')\n","    j = j+1\n","    \n","    y, sr = ta.load(song)\n","    S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","    log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    Y_val.append(m)\n","    X_val.append(log_S.to(device))\n","\n","    fields = song.split('/')\n","    song_name = str(song.split('.')[0])\n","    X_val_songs.append(song_name)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dark\n","Energetic\n","Happy\n","Relaxing\n","Sad\n"]}]},{"cell_type":"markdown","metadata":{"id":"cQcuGJ2wkpF9"},"source":["## Shuffling"]},{"cell_type":"code","metadata":{"id":"dZIlAQkvtT3v"},"source":["train_array = np.array(X_train)\n","label_train_array = np.array(Y_train)\n","song_train_array = np.array(X_train_songs)\n","\n","test_array = np.array(X_test)\n","label_test_array = np.array(Y_test)\n","song_test_array = np.array(X_test_songs)\n","\n","val_array = np.array(X_val)\n","label_val_array = np.array(Y_val)\n","song_val_array = np.array(X_val_songs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZF7hFr9zhEX"},"source":["shuffled_train = np.c_[train_array.reshape(len(train_array), -1), label_train_array.reshape(len(label_train_array), -1), song_train_array.reshape(len(song_train_array), -1)]\n","np.random.shuffle(shuffled_train)\n","\n","shuffled_test = np.c_[test_array.reshape(len(test_array), -1), label_test_array.reshape(len(label_test_array), -1), song_test_array.reshape(len(song_test_array), -1)]\n","np.random.shuffle(shuffled_test)\n","\n","shuffled_val = np.c_[val_array.reshape(len(val_array), -1), label_val_array.reshape(len(label_val_array), -1), song_val_array.reshape(len(song_val_array), -1)]\n","np.random.shuffle(shuffled_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aDiZ1pt4WFK-"},"source":["## Labels Encoder"]},{"cell_type":"code","metadata":{"id":"7HfHMHDQRp9W"},"source":["Y_train_shuffled = np.array([shuffled_train[i][1] for i in range(len(shuffled_train))])\n","Y_test_shuffled = np.array([shuffled_test[i][1] for i in range(len(shuffled_test))])\n","Y_val_shuffled = np.array([shuffled_val[i][1] for i in range(len(shuffled_val))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBx3NTSTiUDB"},"source":["def encode_labels(Y, le=None, enc=None):\n","    \"\"\"Encodes target variables into numbers and then one hot encodings\"\"\"\n","\n","    # initialize encoders\n","    N = Y.shape[0]\n","    \n","    # Encode the labels\n","    if le is None:\n","        le = preprocessing.LabelEncoder()\n","        Y_le = le.fit_transform(Y).reshape(N, 1)\n","    else:\n","        Y_le = le.transform(Y).reshape(N, 1)        \n","        \n","        # convert into one hot encoding\n","        \n","    if enc is None:\n","        enc = preprocessing.OneHotEncoder()\n","        Y_enc = enc.fit_transform(Y_le).toarray()\n","    else:\n","        Y_enc = enc.transform(Y_le).toarray()\n","\n","    # return encoders to re-use on other data\n","    return Y_enc, le, enc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAGXxcnHmhLC"},"source":["# Encode the target vectors into one-hot encoded vectors\n","Y_train, le, enc = encode_labels(Y_train_shuffled)\n","Y_test, le, enc = encode_labels(Y_test_shuffled, le, enc)\n","Y_val, le, enc = encode_labels(Y_val_shuffled, le, enc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KqbY9VSFmihw"},"source":["## Padding"]},{"cell_type":"code","metadata":{"id":"lEmmVZGp2Fu0"},"source":["X_train_shuffled = np.array([shuffled_train[i][0] for i in range(len(shuffled_train))])\n","X_test_shuffled = np.array([shuffled_test[i][0] for i in range(len(shuffled_test))])\n","X_val_shuffled = np.array([shuffled_val[i][0] for i in range(len(shuffled_val))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvsspvGH2J2k"},"source":["S_train_shuffled = np.array([shuffled_train[i][2] for i in range(len(shuffled_train))])\n","S_test_shuffled = np.array([shuffled_test[i][2] for i in range(len(shuffled_test))])\n","S_val_shuffled = np.array([shuffled_val[i][2] for i in range(len(shuffled_val))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CILuG_H-wCK7"},"source":["import torch.nn.functional as F\n","\n","i=0\n","for el in X_train_shuffled:\n","  if el.size()[2]!=X_train_shuffled[0].size()[2]:\n","    last_dim_padding = (0, X_train_shuffled[0].size()[2] - el.size()[2])\n","    X_train_shuffled[i] = F.pad(el, last_dim_padding)\n","    print(i)\n","  i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDyaKhFFs-kO"},"source":["i=0\n","for el in X_test_shuffled:\n","  if el.size()[2]!=X_test_shuffled[0].size()[2]:\n","    last_dim_padding = (0, X_test_shuffled[0].size()[2] - el.size()[2])\n","    X_test_shuffled[i] = F.pad(el, last_dim_padding)\n","    print(i)\n","  i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YqJIUZls_L_"},"source":["i=0\n","for el in X_val_shuffled:\n","  if el.size()[2]!=X_val_shuffled[0].size()[2]:\n","    last_dim_padding = (0, X_val_shuffled[0].size()[2] - el.size()[2])\n","    X_val_shuffled[i] = F.pad(el, last_dim_padding)\n","    print(i)\n","  i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHLGVr3EVQJZ"},"source":["### Reshape data as 2d convolutional tensor shape"]},{"cell_type":"code","metadata":{"id":"k2_DlML9lxJf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631284200029,"user_tz":-120,"elapsed":22,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"b53adb49-24f9-4aa4-e4fb-3a3e926c3c84"},"source":["torch.device(device)\n","    \n","X_train = torch.stack(list(X_train_shuffled)).to(device)\n","print(\"X_stacked train size:\", X_train.size())\n","X_test = torch.stack(list(X_test_shuffled)).to(device)\n","print(\"X_stacked test size:\", X_test.size())\n","X_val = torch.stack(list(X_val_shuffled)).to(device)\n","print(\"X_stacked val size:\", X_val.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_stacked train size: torch.Size([3100, 2, 128, 261])\n","X_stacked test size: torch.Size([270, 2, 128, 261])\n","X_stacked val size: torch.Size([90, 2, 128, 261])\n"]}]},{"cell_type":"code","metadata":{"id":"xKfGK7wrLAH_"},"source":["if X_train.size()[1] > 1:\n","      X_train = torch.unsqueeze(torch.mean(X_train, dim=1), dim=1)\n","if X_test.size()[1] > 1:\n","      X_test = torch.unsqueeze(torch.mean(X_test, dim=1), dim=1)\n","if X_val.size()[1] > 1:\n","      X_val = torch.unsqueeze(torch.mean(X_val, dim=1), dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1pIzgjWRAhc"},"source":["Y_train = torch.tensor(Y_train, dtype=torch.long).to(device)\n","Y_test = torch.tensor(Y_test, dtype=torch.long).to(device)\n","Y_val = torch.tensor(Y_val, dtype=torch.long).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NnHHToMWV7aq"},"source":["#Hyperparameters"]},{"cell_type":"code","metadata":{"id":"XXRXeDwzkb84"},"source":["BATCH_SIZE = 16\n","EPOCHS = 200\n","patience_early_stopping = 15\n","delta_early_stopping = 0.01\n","LEARNING_RATE = 0.001\n","nb_classes = 5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J45wFyJCmvBO"},"source":["#Dataloader"]},{"cell_type":"code","metadata":{"id":"9PuD05j3mq8M"},"source":["def create_data_loader(train_data, batch_size):\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","    return train_dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EZHfv8KuROR6"},"source":["##Creating Dataloader"]},{"cell_type":"code","metadata":{"id":"pBwOn5afmqk6"},"source":["train_data = TensorDataset(X_train, Y_train)\n","train_dataloader = create_data_loader(train_data, BATCH_SIZE)\n","\n","test_data = TensorDataset(X_test, Y_test)\n","test_dataloader = create_data_loader(test_data, BATCH_SIZE)\n","\n","val_data = TensorDataset(X_val, Y_val)\n","val_dataloader = create_data_loader(val_data, BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2TF0lhuNgdO2"},"source":["#Training"]},{"cell_type":"markdown","metadata":{"id":"R7MO8MT0WJ1Z"},"source":["## Model Architecture"]},{"cell_type":"code","metadata":{"id":"qk91KyE6krKr"},"source":["class CRNN(nn.Module):\n","\n","  def __init__(self, n_classes):\n","        super().__init__()\n","        self.norm = nn.BatchNorm2d(128)\n","        self.conv_layers = nn.Sequential(\n","            \n","\n","            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(64),\n","            nn.AvgPool2d((2,2)),\n","            nn.Dropout(0.3),\n","            \n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(128),\n","            nn.AvgPool2d((4,2)),\n","            nn.Dropout(0.3),\n","\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(128),\n","            nn.AvgPool2d((4,2)),\n","            nn.Dropout(0.3),\n","\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(128),\n","            nn.AvgPool2d((4,2)),\n","            nn.Dropout(0.3)\n","        )\n","\n","\n","        self.GRU1 = nn.GRU(128, 32)\n","        self.GRU2 = nn.GRU(32, 32)\n","        \n","        self.out_layers = nn.Sequential(\n","            nn.Dropout(0.3),\n","            nn.Linear(32, n_classes),\n","            #nn.Softmax(dim=1)\n","        )\n","\n","  def forward(self, input_data):\n","        x = input_data.transpose(2, 1)\n","        x = self.norm(x)\n","        x = x.transpose(2, 1)\n","\n","        x = self.conv_layers(x)\n","        x = torch.reshape(x, (x.size()[3], x.size()[0], x.size()[2]*x.size()[1]))\n","\n","        x, _ = self.GRU1(x)\n","        x, _ = self.GRU2(x)        \n","        \n","        x = torch.reshape(x, (x.size()[1], x.size()[0], x.size()[2])) # (16, 56, 32)\n","        x = x[:, -1, :] # (16, 1, 32)\n","\n","        predictions = self.out_layers(x)\n","        return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MCwl4de2WPtK"},"source":["## Trainer Section"]},{"cell_type":"code","metadata":{"id":"z7mDuwbawIav"},"source":["def format_results(preds, trues):\n","\n","  predsBS = []\n","  truesBS = []\n","\n","  for i in range(len(preds)-1):\n","    for j in range(preds[0].size()[0]):\n","      predsBS.append(torch.argmax(preds[i][j]).item())\n","      truesBS.append(torch.argmax(trues[i][j]).item())\n","  for j in range(preds[len(preds)-1].size()[0]):\n","    predsBS.append(torch.argmax(preds[len(preds)-1][j]).item())\n","    truesBS.append(torch.argmax(trues[len(preds)-1][j]).item())\n","\n","  return np.array(predsBS), np.array(truesBS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhDO6Lc8T0IN"},"source":["def get_likely_index(tensor):\n","    return tensor.argmax(dim=-1)\n","\n","def number_of_correct(pred, target):\n","    return pred.squeeze().eq(target).sum().item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N5Dtiln_Ujyn"},"source":["def train_one_epoch(model, data_loader, loss_fn, optimizer, device, val):\n","\n","  if val==1:\n","\n","    val_loss = 0.0\n","    val_steps = 0\n","    total = 0\n","    correct = 0\n","\n","\n","    for inputs, targets in data_loader:\n","      with torch.no_grad():\n","          inputs, targets = inputs.to(device), targets.to(device)\n","          \n","          targets_i = []\n","          j = 0\n","\n","          predictions = model(inputs)\n","          pred = get_likely_index(predictions)\n","\n","          for j in range (targets.size()[0]):\n","            targets_i.append(torch.argmax(targets[j]).item())\n","          \n","          targets_t = torch.LongTensor(targets_i).to(device)\n","\n","          loss = loss_fn(predictions, targets_t)\n","\n","          val_loss += loss\n","\n","          val_steps += 1\n","\n","          correct += number_of_correct(pred, targets_t)\n","\n","          total += targets.size(0)\n","\n","      accuracy = correct / total\n","      loss_epoch = val_loss / val_steps\n","      print(f\"Loss: {loss_epoch}\")\n","      print(f\"Accuracy: {accuracy}\")\n","\n","      return loss_epoch, accuracy\n","\n","  else:\n","    for inputs, targets in data_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        total = 0\n","        correct = 0\n","        targets_i = []\n","        j = 0\n","\n","        predictions = model(inputs)\n","        pred = get_likely_index(predictions)\n","\n","        for j in range (targets.size()[0]):\n","          targets_i.append(torch.argmax(targets[j]).item())\n","        \n","        targets_t = torch.LongTensor(targets_i).to(device)\n","\n","        loss = loss_fn(predictions, targets_t)\n","\n","        correct += number_of_correct(pred, targets_t)\n","        total += targets.size(0)\n","\n","        # backpropagate loss and update weights\n","        optimizer.zero_grad() # at every iteration we calc gradients. these gradients \n","                              # are saved and for this reason we want to reset them\n","        loss.backward()\n","        optimizer.step()\n","\n","    accuracy = correct / total\n","\n","    print(f\"Loss: {loss.item()}\")\n","    print(f\"Accuracy: {accuracy}\")\n","\n","    return loss.item(), accuracy\n","\n","\n","def train(model, train_dataloader, val_dataloader, loss_fn, optimizer, device, epochs, patience, delta):\n","\n","  train_losses = []\n","  val_losses = []\n","  train_accuracies = []\n","  val_accuracies = []\n","  epochs_no_improve = 0\n","  min_loss = None\n","\n","  val = 0\n","  print('Starting Training:')\n","  for i in range(epochs):\n","      print((f\"Epoch {i+1}\"))\n","      loss_epoch, acc_epoch = train_one_epoch(model, train_dataloader, loss_fn, optimizer, device, val)\n","      train_losses.append(loss_epoch)\n","      train_accuracies.append(acc_epoch)\n","      print(\"----------------------------------------\")\n","\n","      if (min_loss is None or loss_epoch <= min_loss-delta):\n","        min_loss = loss_epoch\n","        epochs_no_improve = 0\n","\n","      else:\n","        epochs_no_improve = epochs_no_improve + 1\n","\n","      if epochs_no_improve > patience:\n","        print(\"early stopped. Current loss: \" + str(loss_epoch) + \"\\t min loss: \" + str(min_loss) + \"\\t epochs: \" + str(i))\n","        break\n","\n","  val = 1\n","  print('Starting Validation:')\n","  for j in range(i+1):\n","      print((f\"Val Epoch {j+1}\"))\n","      loss_epoch, acc_epoch = train_one_epoch(model, val_dataloader, loss_fn, optimizer, device, val)\n","      val_losses.append(loss_epoch)\n","      val_accuracies.append(acc_epoch)\n","      print(\"----------------------------------------\")\n","\n","\n","  print(\"Training is done\")\n","  return train_losses, val_losses, train_accuracies, val_accuracies"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQJxNssEiWnx"},"source":["##Train model"]},{"cell_type":"code","metadata":{"id":"-xHoHZ67nO3C"},"source":["CRNN = CRNN(nb_classes).to(device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6Jq0D65l-ho"},"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(CRNN.parameters(), lr=LEARNING_RATE, weight_decay=0.0005)\n","#optimizer = torch.optim.SGD(CRNN.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","\n","train_losses, val_losses, train_accuracies, val_accuracies = train(CRNN, train_dataloader, val_dataloader, loss_fn, optimizer, device, EPOCHS, patience_early_stopping, delta_early_stopping)\n","\n","torch.save(CRNN.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/music_project/team_project/MOOD_x.pth\")\n","print(\"Model trained and stored at MOOD_x.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X2fE1O_qWUz2"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"ZAqeaEk2tY7b"},"source":["from collections import defaultdict\n","from sklearn.utils import shuffle\n","\n","def predict(model, X, Y, S):\n","  \n","    model.eval()\n","    with torch.no_grad():\n","      \n","        prediction_l = []\n","        labels_l = []\n","\n","        songs = np.unique(S)\n","        \n","        for song in songs:\n","          print(song)\n","          X_song = X[S==song]\n","          Y_song = Y[S==song]\n","\n","          predictions = model(X_song)\n","          class_prediction = [torch.argmax(pred).item() for pred in predictions]\n","          print(class_prediction)\n","          actual_prediction = [torch.argmax(label).item() for label in Y_song]\n","\n","          p = defaultdict(int)\n","          t = defaultdict(int)\n","\n","          for i in class_prediction:\n","              p[i] += 1\n","          for i in actual_prediction:\n","              t[i] += 1\n","          \n","          pred_song = max(p.items(), key=lambda x: x[1])[0]\n","          actual_song = max(t.items(), key=lambda x: x[1])[0]\n","\n","          prediction_l.append(pred_song)\n","          labels_l.append(actual_song)\n","\n","\n","    return prediction_l, labels_l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TE8FuMdSwEVI"},"source":["preds, trues = predict(CRNN, X_test, Y_test, S_test_shuffled)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BJABESh7gnjo"},"source":["##Performance Evaluation"]},{"cell_type":"code","metadata":{"id":"ldwS6acjwSXi"},"source":["acc = accuracy_score(trues, preds)\n","f1 = f1_score(trues, preds, average='weighted')\n","cr = classification_report(trues, preds)\n","print(\"accuracy:\", acc)\n","print(\"f1 score:\", f1)\n","print(\"classification report:\")\n","print(cr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrePFOEAps7Z"},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Training Loss\")\n","plt.plot(train_losses,label=\"train\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hsKbSL1bib6J"},"source":["## Deleting slicing folder"]},{"cell_type":"code","metadata":{"id":"Q-AFtzpU8eeq"},"source":["shutil.rmtree('/content/drive/MyDrive/Colab Notebooks/music_project/team_project/mood', ignore_errors=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5vR-H8EgDJZ"},"source":["#TESTING ON NEW INPUTS"]},{"cell_type":"code","metadata":{"id":"TrTEG0TPZ3iM"},"source":["def load_audio_file_segmented(songpath, segment):\n","\n","  sound = None\n","  song_tensor, _= ta.load(songpath)\n","\n","  song_name = songpath.split('/')[-1].split('.')[0]\n","  root = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/song_to_try/'\n","  os.makedirs(root+'slices')\n","\n","  if songpath.endswith('.mp3') or songpath.endswith('.MP3'):\n","      for w in range(0, ((song_tensor.size()[1]//44100)//segment) ):\n","        t1 = segment*(w)*1000\n","        t2 = segment*(w+1)*1000\n","        newAudio = AudioSegment.from_mp3(songpath)\n","        sound = newAudio[t1:t2]\n","        sound.export(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/song_to_try/slices/{song_name+str(w)}.mp3', format=\"mp3\")\n","      newpath = root+'slices/'\n","\n","  elif songpath.endswith('.wav') or songpath.endswith('.WAV'):\n","      for w in range(0,((song_tensor.size()[1]//22050)//segment)):\n","        t1 = segment*(w)*1000\n","        t2 = segment*(w+1)*1000\n","        newAudio = AudioSegment.from_wav(songpath)\n","        sound = newAudio[t1:t2]\n","        sound.export(f'/content/drive/MyDrive/Colab Notebooks/music_project/team_project/song_to_try/slices/{song_name+str(w)}.wav', format=\"wav\")\n","      newpath = root+'slices/' \n","    \n","  return newpath\n","\n","def get_data(songpath):\n","  hop_length = 512\n","  n_fft = 2048\n"," \n","  sound_tensor = []\n","\n","  for _,_,filenames in os.walk(songpath):\n","    for f in filenames:\n","      song = os.path.join(songpath,f'{f}')\n","      y, sr = ta.load(song)\n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","      sliced_sound = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      \n","      if sliced_sound.size()[0] > 1:\n","          sliced_sound = torch.unsqueeze(torch.mean(sliced_sound, dim=0), dim=0)\n","\n","      sound_tensor.append(sliced_sound)\n","  \n","  sound_tensor = torch.stack(sound_tensor).to(device)\n","  return sound_tensor\n","\n","def predict_song(songpath, segmentSize, model, n_classes, le):\n","  newpath = load_audio_file_segmented(songpath, segmentSize)\n","  sound_tensor = get_data(newpath)\n","  shutil.rmtree(newpath, ignore_errors=True)\n","\n","  model.eval()\n","  with torch.no_grad():\n","    class_prediction = []\n","\n","    predictions = model(sound_tensor)\n","    class_prediction = [torch.argmax(pred).item() for pred in predictions]\n","\n","    p = defaultdict(int)\n","    for i in class_prediction:\n","      p[i] += 1\n","            \n","    pred_song = max(p.items(), key=lambda x: x[1])[0]\n","    c = Counter(class_prediction)\n","    outcomes = [(le.inverse_transform([i])[0], float('%.3f'%(c[i] / len(class_prediction) * 100.0))) for i, count in c.most_common()]\n","    print(outcomes)\n","\n","  return outcomes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4Ce2uDuOiDk","executionInfo":{"status":"ok","timestamp":1631286487645,"user_tz":-120,"elapsed":847,"user":{"displayName":"Vincenzo Marcianò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjF3Am1H61m7WHnwLiJCyf7vtckFQVB7xwZfdig=s64","userId":"17501769419042447986"}},"outputId":"d7589082-8cb9-4d0c-e101-dd2ddb211db4"},"source":["CRNN = CRNN(5).to(device=device)\n","PATH = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/MOOD_BEST.pth'\n","CRNN.load_state_dict(torch.load(PATH))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"k6nFiP2PcQPd"},"source":["moods = 'Dark Energetic Happy Relaxing Sad'\n","moods = moods.split()\n","le = preprocessing.LabelEncoder()\n","le.fit_transform(moods)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2Yhsk12jUjg"},"source":["songpath = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/song_to_try/reminder.mp3'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVw2Z-0b0fIl"},"source":["pred = predict_song(songpath,3,CRNN,5,le)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LKtbxiZMiEr9"},"source":["## Multi-Classification visualization"]},{"cell_type":"code","metadata":{"id":"VpsWoi4d8GyY"},"source":["preds_cut = pred[0:4]\n","\n","others_sum = round(100-(pred[0][1]+pred[1][1]+pred[2][1]), 4)\n","others = ('others', others_sum)\n","preds_cut.pop()\n","preds_cut.append(others)\n","preds_cut"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1qMzDfS67dz"},"source":["import seaborn as sns\n","\n","plt.rcParams[\"figure.figsize\"] = [7, 4.5]\n","plt.rcParams[\"figure.autolayout\"] = True\n","ax = sns.barplot(x=[p[0] for p in preds_cut], y=[float(p[1]) for p in preds_cut], palette='PuBuGn_r')\n","patches = ax.patches\n","for i in range(len(patches)):\n","   x = patches[i].get_x() + patches[i].get_width()/2\n","   y = patches[i].get_height()+.01\n","   ax.annotate('{:.2f}%'.format(preds_cut[i][1]), (x, y), ha='center')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AszMsLooWpRJ"},"source":["### PLOTTING SPECTROGRAMS"]},{"cell_type":"code","metadata":{"id":"5q1E45jmpNA3"},"source":["def plot_specgram(waveform, sample_rate, title, xlim=None):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].specgram(waveform[c], Fs=sample_rate)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","  figure.suptitle(title)\n","  plt.show(block=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHB4eBiEKLZb"},"source":["song = '/content/drive/MyDrive/Colab Notebooks/music_project/team_project/song_to_try/715.mp3'\n","title = 'black street'\n","y, sr = ta.load(song)\n","if y.size()[0] > 1:\n","  y = torch.unsqueeze(torch.mean(y, dim=0), dim=0)\n","\n","print(f\"Shape of spectrogram: {y.size()} with sample rate {sr}\")\n","plot_specgram(y,sr,title)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXwhzjbAXOsT"},"source":[""],"execution_count":null,"outputs":[]}]}