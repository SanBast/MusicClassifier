{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Final_GTZAN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dr6VcZDnBFI1"},"source":["# Load Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_XSFEYyjPai","executionInfo":{"status":"ok","timestamp":1632159462339,"user_tz":-120,"elapsed":32014,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"5217a353-9412-448b-d081-4798e57f7dfe"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"OxT9BZhpkNi-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632159472813,"user_tz":-120,"elapsed":7447,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"86e3de29-e6f6-41a1-8916-8faca50d15ed"},"source":["!pip install torchaudio\n","!pip install pydub"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchaudio\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n","Installing collected packages: torchaudio\n","Successfully installed torchaudio-0.9.0\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","metadata":{"id":"qdR-XWXzkBTZ"},"source":["import torch\n","from torch import nn\n","from torch._C import device\n","from torch.nn.modules.activation import ReLU\n","from torch.nn.modules.linear import Linear\n","from torch.utils import data\n","from torch.utils.data import DataLoader, TensorDataset\n","import torchvision\n","from torchvision import datasets\n","from sklearn import preprocessing\n","from torch import Tensor\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix, classification_report\n","from torchvision.transforms import ToTensor\n","from sklearn.model_selection import train_test_split\n","import torchaudio as ta\n","import numpy as np\n","import scipy\n","from scipy import misc\n","import glob\n","import random\n","import math\n","from PIL import Image\n","import os\n","from pydub import AudioSegment\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zyuAMymQLjFb"},"source":["# Check for GPU availability"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLvya0eqk0jG","executionInfo":{"status":"ok","timestamp":1632159479129,"user_tz":-120,"elapsed":7,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"5609cefa-0d4f-45fe-d1d2-1d0e45499940"},"source":["if torch.cuda.is_available():\n","    device = \"cuda\"\n","else:\n","    device = \"cpu\"\n","print(f\"Using {device} device\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"markdown","metadata":{"id":"rSAZVHOXLslT"},"source":["# Genres definition"]},{"cell_type":"code","metadata":{"id":"UU9y3HRcXfwT"},"source":["genres = 'blues classical country disco jazz pop hiphop metal reggae rock'\n","genres = genres.split()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tymM3uR28ToO"},"source":["## Creating folders"]},{"cell_type":"code","metadata":{"id":"uTi-YMve2ixj"},"source":["os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio1sec')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio3sec')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio5sec')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio10sec')\n","\n","\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio1sec/train')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio1sec/test')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio1sec/val')\n","\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio3sec/train')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio3sec/test')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio3sec/val')\n","\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio5sec/train')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio5sec/test')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio5sec/val')\n","\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio10sec/train')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio10sec/test')\n","os.makedirs('/content/drive/MyDrive/team_project/gtzan/audio10sec/val')\n","\n","for g in genres:\n","\n","  path_train = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio1sec/train',f'{g}')\n","  path_test = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio1sec/test',f'{g}')\n","  path_val = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio1sec/val',f'{g}')\n","  os. makedirs(path_train)\n","  os. makedirs(path_test)\n","  os. makedirs(path_val)\n","\n","  path_train = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio3sec/train',f'{g}')\n","  path_test = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio3sec/test',f'{g}')\n","  path_val = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio3sec/val',f'{g}')\n","  os. makedirs(path_train)\n","  os. makedirs(path_test)\n","  os. makedirs(path_val)\n","\n","  path_train = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio5sec/train',f'{g}')\n","  path_test = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio5sec/test',f'{g}')\n","  path_val = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio5sec/val',f'{g}')\n","  os. makedirs(path_train)\n","  os. makedirs(path_test)\n","  os. makedirs(path_val)\n","\n","  path_train = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio10sec/train',f'{g}')\n","  path_test = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio10sec/test',f'{g}')\n","  path_val = os.path.join('/content/drive/MyDrive/team_project/gtzan/audio10sec/val',f'{g}')\n","  os. makedirs(path_train)\n","  os. makedirs(path_test)\n","  os. makedirs(path_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rPpkIrt6kQIy"},"source":["## Time Warping function"]},{"cell_type":"code","metadata":{"id":"W3yWXTWwkGww"},"source":["def sparse_image_warp(img_tensor,\n","                      source_control_point_locations,\n","                      dest_control_point_locations,\n","                      interpolation_order=2,\n","                      regularization_weight=0.0,\n","                      num_boundaries_points=0):\n","    device = img_tensor.device\n","    control_point_flows = (dest_control_point_locations - source_control_point_locations)   \n","    \n","#     clamp_boundaries = num_boundary_points > 0\n","#     boundary_points_per_edge = num_boundary_points - 1\n","    batch_size, image_height, image_width = img_tensor.shape\n","    flattened_grid_locations = get_flat_grid_locations(image_height, image_width, device)\n","\n","    # IGNORED FOR OUR BASIC VERSION...\n","#     flattened_grid_locations = constant_op.constant(\n","#         _expand_to_minibatch(flattened_grid_locations, batch_size), image.dtype)\n","\n","#     if clamp_boundaries:\n","#       (dest_control_point_locations,\n","#        control_point_flows) = _add_zero_flow_controls_at_boundary(\n","#            dest_control_point_locations, control_point_flows, image_height,\n","#            image_width, boundary_points_per_edge)\n","\n","    flattened_flows = interpolate_spline(\n","        dest_control_point_locations,\n","        control_point_flows,\n","        flattened_grid_locations,\n","        interpolation_order,\n","        regularization_weight)\n","\n","    dense_flows = create_dense_flows(flattened_flows, batch_size, image_height, image_width)\n","\n","    warped_image = dense_image_warp(img_tensor, dense_flows)\n","\n","    return warped_image, dense_flows\n","\n","\n","def get_grid_locations(image_height, image_width, device):\n","    y_range = torch.linspace(0, image_height - 1, image_height, device=device)\n","    x_range = torch.linspace(0, image_width - 1, image_width, device=device)\n","    y_grid, x_grid = torch.meshgrid(y_range, x_range)\n","    return torch.stack((y_grid, x_grid), -1)\n","\n","def flatten_grid_locations(grid_locations, image_height, image_width):\n","    return torch.reshape(grid_locations, [image_height * image_width, 2])\n","\n","def create_dense_flows(flattened_flows, batch_size, image_height, image_width):\n","    # possibly .view\n","    return torch.reshape(flattened_flows, [batch_size, image_height, image_width, 2])\n","\n","def get_flat_grid_locations(image_height, image_width, device):\n","    y_range = torch.linspace(0, image_height - 1, image_height, device=device)\n","    x_range = torch.linspace(0, image_width - 1, image_width, device=device)\n","    y_grid, x_grid = torch.meshgrid(y_range, x_range)\n","    return torch.stack((y_grid, x_grid), -1).reshape([image_height * image_width, 2])\n","\n","def create_dense_flows(flattened_flows, batch_size, image_height, image_width):\n","    # possibly .view\n","    return torch.reshape(flattened_flows, [batch_size, image_height, image_width, 2])\n","\n","def interpolate_spline(train_points, train_values, query_points, order, regularization_weight=0.0,):\n","    # First, fit the spline to the observed data.\n","    w, v = solve_interpolation(train_points, train_values, order, regularization_weight)\n","    # Then, evaluate the spline at the query locations.\n","    query_values = apply_interpolation(query_points, train_points, w, v, order)\n","\n","    return query_values\n","\n","def solve_interpolation(train_points, train_values, order, regularization_weight):\n","    device = train_points.device\n","    b, n, d = train_points.shape\n","    k = train_values.shape[-1]\n","\n","    # First, rename variables so that the notation (c, f, w, v, A, B, etc.)\n","    # follows https://en.wikipedia.org/wiki/Polyharmonic_spline.\n","    # To account for python style guidelines we use\n","    # matrix_a for A and matrix_b for B.\n","    \n","    c = train_points\n","    f = train_values.float()\n","    \n","    matrix_a = phi(cross_squared_distance_matrix(c,c), order).unsqueeze(0)  # [b, n, n]\n","#     if regularization_weight > 0:\n","#         batch_identity_matrix = array_ops.expand_dims(\n","#           linalg_ops.eye(n, dtype=c.dtype), 0)\n","#         matrix_a += regularization_weight * batch_identity_matrix\n","\n","    # Append ones to the feature values for the bias term in the linear model.\n","    ones = torch.ones(1, dtype=train_points.dtype, device=device).view([-1, 1, 1])\n","    matrix_b = torch.cat((c, ones), 2).float()  # [b, n, d + 1]\n","\n","    # [b, n + d + 1, n]\n","    left_block = torch.cat((matrix_a, torch.transpose(matrix_b, 2, 1)), 1)\n","\n","    num_b_cols = matrix_b.shape[2]  # d + 1\n","\n","    # In Tensorflow, zeros are used here. Pytorch solve fails with zeros for some reason we don't understand.\n","    # So instead we use very tiny randn values (variance of one, zero mean) on one side of our multiplication.\n","    lhs_zeros = torch.randn((b, num_b_cols, num_b_cols), device=device) / 1e10\n","    right_block = torch.cat((matrix_b, lhs_zeros),\n","                                   1)  # [b, n + d + 1, d + 1]\n","    lhs = torch.cat((left_block, right_block),\n","                           2)  # [b, n + d + 1, n + d + 1]\n","\n","    rhs_zeros = torch.zeros((b, d + 1, k), dtype=train_points.dtype, device=device).float()\n","    rhs = torch.cat((f, rhs_zeros), 1)  # [b, n + d + 1, k]\n","\n","    # Then, solve the linear system and unpack the results.\n","    X, LU = torch.solve(rhs, lhs)\n","    w = X[:, :n, :]\n","    v = X[:, n:, :]\n","\n","    return w, v\n","\n","def cross_squared_distance_matrix(x, y):\n","    \"\"\"Pairwise squared distance between two (batch) matrices' rows (2nd dim).\n","        Computes the pairwise distances between rows of x and rows of y\n","        Args:\n","        x: [batch_size, n, d] float `Tensor`\n","        y: [batch_size, m, d] float `Tensor`\n","        Returns:\n","        squared_dists: [batch_size, n, m] float `Tensor`, where\n","        squared_dists[b,i,j] = ||x[b,i,:] - y[b,j,:]||^2\n","    \"\"\"\n","    x_norm_squared = torch.sum(torch.mul(x, x))\n","    y_norm_squared = torch.sum(torch.mul(y, y))\n","\n","    x_y_transpose = torch.matmul(x.squeeze(0), y.squeeze(0).transpose(0,1))\n","    \n","    # squared_dists[b,i,j] = ||x_bi - y_bj||^2 = x_bi'x_bi- 2x_bi'x_bj + x_bj'x_bj\n","    squared_dists = x_norm_squared - 2 * x_y_transpose + y_norm_squared\n","\n","    return squared_dists.float()\n","\n","def phi(r, order):\n","    \"\"\"Coordinate-wise nonlinearity used to define the order of the interpolation.\n","    See https://en.wikipedia.org/wiki/Polyharmonic_spline for the definition.\n","    Args:\n","    r: input op\n","    order: interpolation order\n","    Returns:\n","    phi_k evaluated coordinate-wise on r, for k = r\n","    \"\"\"\n","    EPSILON=torch.tensor(1e-10, device=r.device)\n","    # using EPSILON prevents log(0), sqrt0), etc.\n","    # sqrt(0) is well-defined, but its gradient is not\n","    if order == 1:\n","        r = torch.max(r, EPSILON)\n","        r = torch.sqrt(r)\n","        return r\n","    elif order == 2:\n","        return 0.5 * r * torch.log(torch.max(r, EPSILON))\n","    elif order == 4:\n","        return 0.5 * torch.square(r) * torch.log(torch.max(r, EPSILON))\n","    elif order % 2 == 0:\n","        r = torch.max(r, EPSILON)\n","        return 0.5 * torch.pow(r, 0.5 * order) * torch.log(r)\n","    else:\n","        r = torch.max(r, EPSILON)\n","        return torch.pow(r, 0.5 * order)\n","  \n","def apply_interpolation(query_points, train_points, w, v, order):\n","    \"\"\"Apply polyharmonic interpolation model to data.\n","    Given coefficients w and v for the interpolation model, we evaluate\n","    interpolated function values at query_points.\n","    Args:\n","    query_points: `[b, m, d]` x values to evaluate the interpolation at\n","    train_points: `[b, n, d]` x values that act as the interpolation centers\n","                    ( the c variables in the wikipedia article)\n","    w: `[b, n, k]` weights on each interpolation center\n","    v: `[b, d, k]` weights on each input dimension\n","    order: order of the interpolation\n","    Returns:\n","    Polyharmonic interpolation evaluated at points defined in query_points.\n","    \"\"\"\n","    query_points = query_points.unsqueeze(0)\n","    # First, compute the contribution from the rbf term.\n","    pairwise_dists = cross_squared_distance_matrix(query_points.float(), train_points.float())\n","    phi_pairwise_dists = phi(pairwise_dists, order)\n","\n","    rbf_term = torch.matmul(phi_pairwise_dists, w)\n","\n","    # Then, compute the contribution from the linear term.\n","    # Pad query_points with ones, for the bias term in the linear model.\n","    ones = torch.ones_like(query_points[..., :1])\n","    query_points_pad = torch.cat((\n","      query_points,\n","      ones\n","    ), 2).float()\n","    linear_term = torch.matmul(query_points_pad, v)\n","\n","    return rbf_term + linear_term\n","def dense_image_warp(image, flow):\n","    \"\"\"Image warping using per-pixel flow vectors.\n","    Apply a non-linear warp to the image, where the warp is specified by a dense\n","    flow field of offset vectors that define the correspondences of pixel values\n","    in the output image back to locations in the  source image. Specifically, the\n","    pixel value at output[b, j, i, c] is\n","    images[b, j - flow[b, j, i, 0], i - flow[b, j, i, 1], c].\n","    The locations specified by this formula do not necessarily map to an int\n","    index. Therefore, the pixel value is obtained by bilinear\n","    interpolation of the 4 nearest pixels around\n","    (b, j - flow[b, j, i, 0], i - flow[b, j, i, 1]). For locations outside\n","    of the image, we use the nearest pixel values at the image boundary.\n","    Args:\n","    image: 4-D float `Tensor` with shape `[batch, height, width, channels]`.\n","    flow: A 4-D float `Tensor` with shape `[batch, height, width, 2]`.\n","    name: A name for the operation (optional).\n","    Note that image and flow can be of type tf.half, tf.float32, or tf.float64,\n","    and do not necessarily have to be the same type.\n","    Returns:\n","    A 4-D float `Tensor` with shape`[batch, height, width, channels]`\n","    and same type as input image.\n","    Raises:\n","    ValueError: if height < 2 or width < 2 or the inputs have the wrong number\n","    of dimensions.\n","    \"\"\"\n","    image = image.unsqueeze(3) # add a single channel dimension to image tensor\n","    batch_size, height, width, channels = image.shape\n","    device = image.device\n","\n","    # The flow is defined on the image grid. Turn the flow into a list of query\n","    # points in the grid space.\n","    grid_x, grid_y = torch.meshgrid(\n","        torch.arange(width, device=device), torch.arange(height, device=device))\n","    \n","    stacked_grid = torch.stack((grid_y, grid_x), dim=2).float()\n","    \n","    batched_grid = stacked_grid.unsqueeze(-1).permute(3, 1, 0, 2)\n","    \n","    query_points_on_grid = batched_grid - flow\n","    query_points_flattened = torch.reshape(query_points_on_grid,\n","                                               [batch_size, height * width, 2])\n","    # Compute values at the query points, then reshape the result back to the\n","    # image grid.\n","    interpolated = interpolate_bilinear(image, query_points_flattened)\n","    interpolated = torch.reshape(interpolated,\n","                                     [batch_size, height, width, channels])\n","    return interpolated\n","\n","def interpolate_bilinear(grid,\n","                         query_points,\n","                         name='interpolate_bilinear',\n","                         indexing='ij'):\n","    \"\"\"Similar to Matlab's interp2 function.\n","    Finds values for query points on a grid using bilinear interpolation.\n","    Args:\n","    grid: a 4-D float `Tensor` of shape `[batch, height, width, channels]`.\n","    query_points: a 3-D float `Tensor` of N points with shape `[batch, N, 2]`.\n","    name: a name for the operation (optional).\n","    indexing: whether the query points are specified as row and column (ij),\n","      or Cartesian coordinates (xy).\n","    Returns:\n","    values: a 3-D `Tensor` with shape `[batch, N, channels]`\n","    Raises:\n","    ValueError: if the indexing mode is invalid, or if the shape of the inputs\n","      invalid.\n","    \"\"\"\n","    if indexing != 'ij' and indexing != 'xy':\n","        raise ValueError('Indexing mode must be \\'ij\\' or \\'xy\\'')\n","\n","\n","    shape = grid.shape\n","    if len(shape) != 4:\n","      msg = 'Grid must be 4 dimensional. Received size: '\n","      raise ValueError(msg + str(grid.shape))\n","\n","    batch_size, height, width, channels = grid.shape\n","\n","    shape = [batch_size, height, width, channels]\n","    query_type = query_points.dtype\n","    grid_type = grid.dtype\n","    grid_device = grid.device\n","\n","    num_queries = query_points.shape[1]\n","\n","    alphas = []\n","    floors = []\n","    ceils = []\n","    index_order = [0, 1] if indexing == 'ij' else [1, 0]\n","    unstacked_query_points = query_points.unbind(2)\n","\n","    for dim in index_order:\n","        queries = unstacked_query_points[dim]\n","\n","        size_in_indexing_dimension = shape[dim + 1]\n","\n","        # max_floor is size_in_indexing_dimension - 2 so that max_floor + 1\n","        # is still a valid index into the grid.\n","        max_floor = torch.tensor(size_in_indexing_dimension - 2, dtype=query_type, device=grid_device)\n","        min_floor = torch.tensor(0.0, dtype=query_type, device=grid_device)\n","        maxx = torch.max(min_floor, torch.floor(queries))\n","        floor = torch.min(maxx, max_floor)\n","        int_floor = floor.long()\n","        floors.append(int_floor)\n","        ceil = int_floor + 1\n","        ceils.append(ceil)\n","\n","        # alpha has the same type as the grid, as we will directly use alpha\n","        # when taking linear combinations of pixel values from the image.\n","        \n","        \n","        alpha = torch.tensor((queries - floor), dtype=grid_type, device=grid_device)\n","        min_alpha = torch.tensor(0.0, dtype=grid_type, device=grid_device)\n","        max_alpha = torch.tensor(1.0, dtype=grid_type, device=grid_device)\n","        alpha = torch.min(torch.max(min_alpha, alpha), max_alpha)\n","\n","        # Expand alpha to [b, n, 1] so we can use broadcasting\n","        # (since the alpha values don't depend on the channel).\n","        alpha = torch.unsqueeze(alpha, 2)\n","        alphas.append(alpha)\n","\n","    flattened_grid = torch.reshape(\n","      grid, [batch_size * height * width, channels])\n","    batch_offsets = torch.reshape(\n","      torch.arange(batch_size, device=grid_device) * height * width, [batch_size, 1])\n","\n","    # This wraps array_ops.gather. We reshape the image data such that the\n","    # batch, y, and x coordinates are pulled into the first dimension.\n","    # Then we gather. Finally, we reshape the output back. It's possible this\n","    # code would be made simpler by using array_ops.gather_nd.\n","    def gather(y_coords, x_coords, name):\n","        linear_coordinates = batch_offsets + y_coords * width + x_coords\n","        gathered_values = torch.gather(flattened_grid.t(), 1, linear_coordinates)\n","        return torch.reshape(gathered_values,\n","                                 [batch_size, num_queries, channels])\n","\n","    # grab the pixel values in the 4 corners around each query point\n","    top_left = gather(floors[0], floors[1], 'top_left')\n","    top_right = gather(floors[0], ceils[1], 'top_right')\n","    bottom_left = gather(ceils[0], floors[1], 'bottom_left')\n","    bottom_right = gather(ceils[0], ceils[1], 'bottom_right')\n","\n","    interp_top = alphas[1] * (top_right - top_left) + top_left\n","    interp_bottom = alphas[1] * (bottom_right - bottom_left) + bottom_left\n","    interp = alphas[0] * (interp_bottom - interp_top) + interp_top\n","\n","    return interp\n","\n","def time_warp(spec, W=20):\n","    num_rows = spec.shape[1]\n","    spec_len = spec.shape[2]\n","    device = spec.device\n","    \n","    y = num_rows//2\n","    horizontal_line_at_ctr = spec[0][y]\n","    assert len(horizontal_line_at_ctr) == spec_len\n","    \n","    point_to_warp = horizontal_line_at_ctr[random.randrange(W, spec_len - W)]\n","    assert isinstance(point_to_warp, torch.Tensor)\n","\n","    # Uniform distribution from (0,W) with chance to be up to W negative\n","    dist_to_warp = random.randrange(-W, W)\n","    src_pts, dest_pts = (torch.tensor([[[y, point_to_warp]]], device=device), \n","                         torch.tensor([[[y, point_to_warp + dist_to_warp]]], device=device))\n","    warped_spectro, dense_flows = sparse_image_warp(spec, src_pts, dest_pts)\n","    return warped_spectro.squeeze(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tRR5hriTUH_L"},"source":["# Creating Train/Test/Val Set and Mel-Spectrograms"]},{"cell_type":"code","metadata":{"id":"V8qkX8fBX6C_"},"source":["#select the segmentation window (1, 3, 5, 10) seconds\n","segment = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A43g4rhkRjSi"},"source":["directory = '/content/drive/MyDrive/team_project/genres_original'\n","\n","i=0\n","for g in genres:\n","  print(g)\n","  j=0\n","  filenames = os.listdir(os.path.join(directory,f\"{g}\"))\n"," \n","  train_files, test_files = train_test_split(filenames, test_size=0.1, random_state=42)\n","  train_files, val_file = train_test_split(train_files, test_size=0.2, random_state=42)\n","\n","  for f in test_files:\n","    j = j+1\n","    song  =  os.path.join(f'/content/drive/MyDrive/team_project/genres_original/{g}',f'{f}')\n","    for w in range(0,30//segment):\n","      i = i+1\n","      t1 = segment*(w)*1000\n","      t2 = segment*(w+1)*1000\n","      path = '/content/drive/MyDrive/team_project/gtzan/audio'+str(segment)+'sec/test/'+g+'/'+f+'_'+str(j)+str(w)+'.wav'\n","      newAudio = AudioSegment.from_wav(song)\n","      new = newAudio[t1:t2]\n","      new.export(path, format=\"wav\")\n","\n","  i=0\n","  j=0\n","  for f in train_files:\n","    j = j+1\n","    song  =  os.path.join(f'/content/drive/MyDrive/team_project/genres_original/{g}',f'{f}')\n","    for w in range(0,30//segment):\n","      i = i+1\n","      t1 = segment*(w)*1000\n","      t2 = segment*(w+1)*1000\n","      path = '/content/drive/MyDrive/team_project/gtzan/audio'+str(segment)+'sec/train/'+g+'/'+f+'_'+str(j)+str(w)+'.wav'\n","      newAudio = AudioSegment.from_wav(song)\n","      new = newAudio[t1:t2]\n","      new.export(path, format=\"wav\")\n","\n","  i=0\n","  j=0\n","  for f in val_file:\n","    j+=1\n","    song  =  os.path.join(f'/content/drive/MyDrive/team_project/genres_original/{g}',f'{f}')\n","    for w in range(0,30//segment):\n","        i = i+1\n","        t1 = segment*(w)*1000\n","        t2 = segment*(w+1)*1000\n","        path = '/content/drive/MyDrive/team_project/gtzan/audio'+str(segment)+'sec/val/'+g+'/'+f+'_'+str(j)+str(w)+'.wav'\n","        newAudio = AudioSegment.from_wav(song)\n","        new = newAudio[t1:t2]\n","        new.export(path, format=\"wav\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yu3536Lc8ZyD"},"source":["## Define augmentation techniques"]},{"cell_type":"code","metadata":{"id":"e-afJDl0YplH"},"source":["#choose the augmentation technique\n","augmentations = ['None', 'time_mask', 'frequ_mask', 'time_warp', 'noise']\n","aug = augmentations[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LlOdVzIoUb0f"},"source":["## TRAIN SPLIT"]},{"cell_type":"code","metadata":{"id":"MR1030465JHL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632165466937,"user_tz":-120,"elapsed":5970107,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"ba08107f-2376-4d7c-c123-e6458aa69ca0"},"source":["X_train = []\n","Y_train = []\n","X_train_songs = []\n","\n","sr = 22050\n","hop_length = 512\n","n_fft = 2048\n","\n","noise_url = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n","noise = ta.load(noise_url)[0]\n","  \n","\n","for g in genres:\n","  j = 0\n","  print(g)\n","  for filename in os.listdir(os.path.join('/content/drive/MyDrive/team_project/gtzan/audio'+str(segment)+'sec/train',f\"{g}\")):\n","    song  =  os.path.join(f'/content/drive/MyDrive/team_project/gtzan/audio{segment}sec/train/{g}',f'{filename}')\n","    j = j+1\n","    \n","    y, sr = ta.load(song)\n","    S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","    log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    #augmentation:\n","\n","    if aug =='None':\n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","      log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    if aug =='noise':\n","      noise_ = noise[:,:y.shape[1]]\n","      \n","\n","      song_power = y.norm(p=2)\n","      noise_power = noise_.norm(p=2)\n","\n","      snr = math.exp(20 / 10)\n","      scale = snr * noise_power / song_power\n","      noisy_song = (scale * y + noise_) / 2\n","    \n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(noisy_song) #(N, channel\\ num mels\\ time)\n","      log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n"," \n","    if aug == 'time_mask':\n","      time_mask = ta.transforms.TimeMasking(time_mask_param=50)\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = time_mask(log_S)\n","\n","    if aug == 'freq_mask':\n","      freq_mask = ta.transforms.FrequencyMasking(freq_mask_param=60)\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = freq_mask(log_S)\n","\n","    if aug == 'time_warp':\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = time_warp(log_S)\n","\n","\n","    Y_train.append(g)\n","    Y_train.append(g)\n","    X_train.append(log_S.to(device))\n","    X_train.append(log_S_aug.to(device))\n","    fields = song.split('/')\n","    song_name = (str(song.split('.')[0])+str(song.split('.')[1])).split('/')[len(fields)-1]\n","    X_train_songs.append(song_name)\n","    X_train_songs.append(song_name)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["blues\n","classical\n","country\n","disco\n","jazz\n","pop\n","hiphop\n","metal\n","reggae\n","rock\n"]}]},{"cell_type":"markdown","metadata":{"id":"WbVuWJzsUi3t"},"source":["## TEST SPLIT"]},{"cell_type":"code","metadata":{"id":"EzGGHcriUhHP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632166199267,"user_tz":-120,"elapsed":671601,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"2e3e5c38-0a91-43d7-ea4b-adba1060c30c"},"source":["X_test = []\n","X_test_songs = []\n","Y_test = []\n","\n","sr = 22050\n","hop_length = 512\n","n_fft = 2048\n","\n","noise_url = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n","noise = ta.load(noise_url)[0]\n","\n","for g in genres:\n","  j = 0\n","  print(g)\n","  for filename in os.listdir(os.path.join('/content/drive/MyDrive/team_project/gtzan/audio'+str(segment)+'sec/test',f\"{g}\")):\n","    song  =  os.path.join(f'/content/drive/MyDrive/team_project/gtzan/audio{segment}sec/test/{g}',f'{filename}')\n","    j = j+1\n","    \n","    y, sr = ta.load(song)\n","    S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","    log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    #augmentation:\n","\n","    if aug =='None':\n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","      log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    if aug =='noise':\n","\n","      noise_ = noise[:,:y.shape[1]]\n","  \n","\n","      song_power = y.norm(p=2)\n","      noise_power = noise_.norm(p=2)\n","\n","      snr = math.exp(20 / 10)\n","      scale = snr * noise_power / song_power\n","      noisy_song = (scale * y + noise_) / 2\n","    \n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(noisy_song) #(N, channel\\ num mels\\ time)\n","      log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    if aug == 'time_mask':\n","      time_mask = ta.transforms.TimeMasking(time_mask_param=50)\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = time_mask(log_S)\n","\n","    if aug == 'freq_mask':\n","      freq_mask = ta.transforms.FrequencyMasking(freq_mask_param=60)\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = freq_mask(log_S)\n","\n","    if aug == 'time_warp':\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = time_warp(log_S)\n","\n","    \n","\n","    Y_test.append(g)\n","    Y_test.append(g)\n","\n","    X_test.append(log_S.to(device))\n","    X_test.append(log_S_aug.to(device))\n","\n","    fields = song.split('/')\n","    song_name = (str(song.split('.')[0])+str(song.split('.')[1])).split('/')[len(fields)-1]\n","    X_test_songs.append(song_name)\n","    X_test_songs.append(song_name)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["blues\n","classical\n","country\n","disco\n","jazz\n","pop\n","hiphop\n","metal\n","reggae\n","rock\n"]}]},{"cell_type":"markdown","metadata":{"id":"0Ipryf8dUvMe"},"source":["## VAL SPLIT"]},{"cell_type":"code","metadata":{"id":"5MkWSi-xUhV1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632166302003,"user_tz":-120,"elapsed":70153,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"cde52c98-e571-4e98-a923-3dda9c3bac9f"},"source":["X_val = []\n","X_val_songs = []\n","Y_val = []\n","\n","sr = 22050\n","hop_length = 512\n","n_fft = 2048\n","\n","noise_url = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n","noise = ta.load(noise_url)[0]\n","\n","for g in genres:\n","  j = 0\n","  print(g)\n","  for filename in os.listdir(os.path.join('/content/drive/MyDrive/team_project/gtzan/audio'+str(segment)+'sec/val',f\"{g}\")):\n","    song  =  os.path.join(f'/content/drive/MyDrive/team_project/gtzan/audio{segment}sec/val/{g}',f'{filename}')\n","    j = j+1\n","    \n","    y, sr = ta.load(song)\n","    S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","    log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","    #augmentation\n","\n","    if aug =='None':\n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(N, channel\\ num mels\\ time)\n","      log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","    if aug =='noise':\n","\n","      noise_ = noise[:,:y.shape[1]]\n","\n","      song_power = y.norm(p=2)\n","      noise_power = noise_.norm(p=2)\n","\n","      snr = math.exp(20 / 10)\n","      scale = snr * noise_power / song_power\n","      noisy_song = (scale * y + noise_) / 2\n","    \n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(noisy_song) #(N, channel\\ num mels\\ time)\n","      log_S_aug = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","\n","\n","    if aug == 'time_mask':\n","      time_mask = ta.transforms.TimeMasking(time_mask_param=50)\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = time_mask(log_S)\n","\n","    if aug == 'freq_mask':\n","      freq_mask = ta.transforms.FrequencyMasking(freq_mask_param=60)\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = freq_mask(log_S)\n","\n","    if aug == 'time_warp':\n","      #S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y)\n","      #log_S = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      log_S_aug = time_warp(log_S)\n","    \n","\n","    Y_val.append(g)\n","    Y_val.append(g)\n","\n","    X_val.append(log_S.to(device))\n","    X_val.append(log_S_aug.to(device))\n","\n","    fields = song.split('/')\n","    song_name = (str(song.split('.')[0])+str(song.split('.')[1])).split('/')[len(fields)-1]\n","    X_val_songs.append(song_name)\n","    X_val_songs.append(song_name)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["blues\n","classical\n","country\n","disco\n","jazz\n","pop\n","hiphop\n","metal\n","reggae\n","rock\n"]}]},{"cell_type":"markdown","metadata":{"id":"MVdXG0aOkmIR"},"source":["## Shuffling"]},{"cell_type":"code","metadata":{"id":"dZIlAQkvtT3v"},"source":["train_array = np.array(X_train)\n","label_train_array = np.array(Y_train)\n","song_train_array = np.array(X_train_songs)\n","\n","test_array = np.array(X_test)\n","label_test_array = np.array(Y_test)\n","song_test_array = np.array(X_test_songs)\n","\n","val_array = np.array(X_val)\n","label_val_array = np.array(Y_val)\n","song_val_array = np.array(X_val_songs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZF7hFr9zhEX"},"source":["shuffled_train = np.c_[train_array.reshape(len(train_array), -1), label_train_array.reshape(len(label_train_array), -1), song_train_array.reshape(len(song_train_array), -1)]\n","np.random.shuffle(shuffled_train)\n","\n","shuffled_test = np.c_[test_array.reshape(len(test_array), -1), label_test_array.reshape(len(label_test_array), -1), song_test_array.reshape(len(song_test_array), -1)]\n","np.random.shuffle(shuffled_test)\n","\n","shuffled_val = np.c_[val_array.reshape(len(val_array), -1), label_val_array.reshape(len(label_val_array), -1), song_val_array.reshape(len(song_val_array), -1)]\n","np.random.shuffle(shuffled_val)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aDiZ1pt4WFK-"},"source":["## Labels Encoder"]},{"cell_type":"code","metadata":{"id":"7HfHMHDQRp9W"},"source":["Y_train_shuffled = np.array([shuffled_train[i][1] for i in range(len(shuffled_train))])\n","Y_test_shuffled = np.array([shuffled_test[i][1] for i in range(len(shuffled_test))])\n","Y_val_shuffled = np.array([shuffled_val[i][1] for i in range(len(shuffled_val))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBx3NTSTiUDB"},"source":["def encode_labels(Y, le=None, enc=None):\n","    \"\"\"Encodes target variables into numbers and then one hot encodings\"\"\"\n","\n","    # initialize encoders\n","    N = Y.shape[0]\n","    \n","    # Encode the labels\n","    if le is None:\n","        le = preprocessing.LabelEncoder()\n","        Y_le = le.fit_transform(Y).reshape(N, 1)\n","    else:\n","        Y_le = le.transform(Y).reshape(N, 1)        \n","        \n","        # convert into one hot encoding\n","        \n","    if enc is None:\n","        enc = preprocessing.OneHotEncoder()\n","        Y_enc = enc.fit_transform(Y_le).toarray()\n","    else:\n","        Y_enc = enc.transform(Y_le).toarray()\n","\n","    # return encoders to re-use on other data\n","    return Y_enc, le, enc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAGXxcnHmhLC"},"source":["# Encode the target vectors into one-hot encoded vectors\n","Y_train, le, enc = encode_labels(Y_train_shuffled)\n","Y_test, le, enc = encode_labels(Y_test_shuffled, le, enc)\n","Y_val, le, enc = encode_labels(Y_val_shuffled, le, enc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KqbY9VSFmihw"},"source":["## Padding"]},{"cell_type":"code","metadata":{"id":"lEmmVZGp2Fu0"},"source":["X_train_shuffled = np.array([shuffled_train[i][0] for i in range(len(shuffled_train))])\n","X_test_shuffled = np.array([shuffled_test[i][0] for i in range(len(shuffled_test))])\n","X_val_shuffled = np.array([shuffled_val[i][0] for i in range(len(shuffled_val))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvsspvGH2J2k"},"source":["S_train_shuffled = np.array([shuffled_train[i][2] for i in range(len(shuffled_train))])\n","S_test_shuffled = np.array([shuffled_test[i][2] for i in range(len(shuffled_test))])\n","S_val_shuffled = np.array([shuffled_val[i][2] for i in range(len(shuffled_val))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CILuG_H-wCK7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632166343420,"user_tz":-120,"elapsed":389,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"20f141b3-939a-48ec-fd9c-3e15cce52998"},"source":["i=0\n","for el in X_train_shuffled:\n","  if el.size()[2]!=X_train_shuffled[0].size()[2]:\n","    last_dim_padding = (0, X_train_shuffled[0].size()[2] - el.size()[2])\n","    X_train_shuffled[i] = F.pad(el, last_dim_padding)\n","    print(i)\n","  i+=1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["679\n","2522\n","3384\n","5767\n","9678\n","11021\n","11988\n","17703\n"]}]},{"cell_type":"code","metadata":{"id":"xDyaKhFFs-kO"},"source":["i=0\n","for el in X_test_shuffled:\n","  if el.size()[2]!=X_test_shuffled[0].size()[2]:\n","    last_dim_padding = (0, X_test_shuffled[0].size()[2] - el.size()[2])\n","    X_test_shuffled[i] = F.pad(el, last_dim_padding)\n","    print(i)\n","  i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YqJIUZls_L_"},"source":["i=0\n","for el in X_val_shuffled:\n","  if el.size()[2]!=X_val_shuffled[0].size()[2]:\n","    last_dim_padding = (0, X_val_shuffled[0].size()[2] - el.size()[2])\n","    X_val_shuffled[i] = F.pad(el, last_dim_padding)\n","    print(i)\n","  i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHLGVr3EVQJZ"},"source":["## Reshape data as 2d convolutional tensor shape"]},{"cell_type":"code","metadata":{"id":"k2_DlML9lxJf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632166352186,"user_tz":-120,"elapsed":9,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"fe35a935-c88f-43c0-e974-0689a477f371"},"source":["torch.device(device)\n","    \n","X_train = torch.stack(list(X_train_shuffled)).to(device)\n","print(\"X_stacked train size:\", X_train.size())\n","X_test = torch.stack(list(X_test_shuffled)).to(device)\n","print(\"X_stacked test size:\", X_test.size())\n","X_val = torch.stack(list(X_val_shuffled)).to(device)\n","print(\"X_stacked val size:\", X_val.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_stacked train size: torch.Size([17780, 1, 128, 130])\n","X_stacked test size: torch.Size([2000, 1, 128, 130])\n","X_stacked val size: torch.Size([200, 1, 128, 130])\n"]}]},{"cell_type":"code","metadata":{"id":"E1pIzgjWRAhc"},"source":["Y_train = torch.tensor(Y_train, dtype=torch.long).to(device)\n","Y_test = torch.tensor(Y_test, dtype=torch.long).to(device)\n","Y_val = torch.tensor(Y_val, dtype=torch.long).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NnHHToMWV7aq"},"source":["#Hyperparameters"]},{"cell_type":"code","metadata":{"id":"XXRXeDwzkb84"},"source":["BATCH_SIZE = 16\n","EPOCHS = 200\n","patience_early_stopping = 100\n","delta_early_stopping = 0.01\n","LEARNING_RATE = 0.001\n","nb_classes = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J45wFyJCmvBO"},"source":["# Dataloader"]},{"cell_type":"code","metadata":{"id":"9PuD05j3mq8M"},"source":["def create_data_loader(train_data, batch_size):\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","    return train_dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBwOn5afmqk6"},"source":["train_data = TensorDataset(X_train, Y_train)\n","train_dataloader = create_data_loader(train_data, BATCH_SIZE)\n","\n","test_data = TensorDataset(X_test, Y_test)\n","test_dataloader = create_data_loader(test_data, BATCH_SIZE)\n","\n","val_data = TensorDataset(X_val, Y_val)\n","val_dataloader = create_data_loader(val_data, BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fh-ms4yhcCko"},"source":["#Training"]},{"cell_type":"markdown","metadata":{"id":"R7MO8MT0WJ1Z"},"source":["## Model Architecture"]},{"cell_type":"code","metadata":{"id":"qk91KyE6krKr"},"source":["class CRNN(nn.Module):\n","\n","  def __init__(self, n_classes):\n","        super().__init__()\n","        self.norm = nn.BatchNorm2d(128) #---> normalize across frequency\n","        self.conv_layers = nn.Sequential(\n","            \n","\n","            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(64),\n","            nn.MaxPool2d((2,2)),\n","            nn.Dropout(0.3),\n","            \n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(128),\n","            nn.MaxPool2d((4,2)),\n","            nn.Dropout(0.3),\n","\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(128),\n","            nn.MaxPool2d((4,2)),\n","            nn.Dropout(0.3),\n","\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ELU(),\n","            nn.BatchNorm2d(128),\n","            nn.MaxPool2d((4,2)),\n","            nn.Dropout(0.3)\n","        )\n","\n","\n","        self.GRU1 = nn.GRU(128, 32)\n","        self.GRU2 = nn.GRU(32, 32)\n","        \n","        self.out_layers = nn.Sequential(\n","            nn.Dropout(0.3),\n","            nn.Linear(32, n_classes)\n","            #nn.Softmax(dim=1)\n","        )\n","\n","  def forward(self, input_data):\n","        x = input_data.transpose(2, 1) \n","        x = self.norm(x)  # --> (B, F, C, T)\n","        x = x.transpose(2, 1)\n","\n","        x = self.conv_layers(x) # --> (B, C, F, T)\n","        x = torch.reshape(x, (x.size()[3], x.size()[0], x.size()[2]*x.size()[1]))  # --> (T, B, C*F)\n","\n","        x, _ = self.GRU1(x)\n","        x, _ = self.GRU2(x)        \n","        \n","        x = torch.reshape(x, (x.size()[1], x.size()[0], x.size()[2])) # (16, 56, 32)\n","        x = x[:, -1, :] # (16, 1, 32)\n","\n","        predictions = self.out_layers(x)\n","        return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MCwl4de2WPtK"},"source":["## Trainer "]},{"cell_type":"code","metadata":{"id":"hhDO6Lc8T0IN"},"source":["def get_likely_index(tensor):\n","    return tensor.argmax(dim=-1)\n","\n","def number_of_correct(pred, target):\n","    return pred.squeeze().eq(target).sum().item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N5Dtiln_Ujyn"},"source":["def train_one_epoch(model, data_loader, loss_fn, optimizer, device, val):\n","\n","  if val==1:\n","\n","    val_loss = 0.0\n","    val_steps = 0\n","    total = 0\n","    correct = 0\n","\n","\n","    for inputs, targets in data_loader:\n","      with torch.no_grad():\n","          inputs, targets = inputs.to(device), targets.to(device)\n","          \n","          targets_i = []\n","          j = 0\n","\n","          predictions = model(inputs)\n","          pred = get_likely_index(predictions)\n","\n","          for j in range (targets.size()[0]):\n","            targets_i.append(torch.argmax(targets[j]).item())\n","          \n","          targets_t = torch.LongTensor(targets_i).to(device)\n","\n","          loss = loss_fn(predictions, targets_t)\n","\n","          val_loss += loss\n","\n","          val_steps += 1\n","\n","          correct += number_of_correct(pred, targets_t)\n","\n","          total += targets.size(0)\n","\n","      accuracy = correct / total\n","      loss_epoch = val_loss / val_steps\n","      print(f\"Loss: {loss_epoch}\")\n","      print(f\"Accuracy: {accuracy}\")\n","\n","      return loss_epoch, accuracy\n","\n","  else:\n","    for inputs, targets in data_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        total = 0\n","        correct = 0\n","        targets_i = []\n","        j = 0\n","\n","        predictions = model(inputs)\n","        pred = get_likely_index(predictions)\n","\n","        for j in range (targets.size()[0]):\n","          targets_i.append(torch.argmax(targets[j]).item())\n","        \n","        targets_t = torch.LongTensor(targets_i).to(device)\n","\n","        loss = loss_fn(predictions, targets_t)\n","\n","        correct += number_of_correct(pred, targets_t)\n","        total += targets.size(0)\n","\n","        # backpropagate loss and update weights\n","        optimizer.zero_grad() # at every iteration we calc gradients. these gradients \n","                              # are saved and for this reason we want to reset them\n","        loss.backward()\n","        optimizer.step()\n","\n","    accuracy = correct / total\n","\n","    print(f\"Loss: {loss.item()}\")\n","    print(f\"Accuracy: {accuracy}\")\n","\n","    return loss.item(), accuracy\n","\n","\n","def train(model, train_dataloader, val_dataloader, loss_fn, optimizer, device, epochs, patience, delta):\n","\n","  train_losses = []\n","  val_losses = []\n","  train_accuracies = []\n","  val_accuracies = []\n","  epochs_no_improve = 0\n","  min_loss = None\n","\n","  val = 0\n","  print(\"Starting Training:\")\n","  for i in range(epochs):\n","      print((f\"Epoch {i+1}\"))\n","      loss_epoch, acc_epoch = train_one_epoch(model, train_dataloader, loss_fn, optimizer, device, val)\n","      train_losses.append(loss_epoch)\n","      train_accuracies.append(acc_epoch)\n","      print(\"----------------------------------------\")\n","\n","      if (min_loss is None or loss_epoch <= min_loss-delta):\n","        min_loss = loss_epoch\n","        epochs_no_improve = 0\n","\n","      else:\n","        epochs_no_improve = epochs_no_improve + 1\n","\n","      if epochs_no_improve > patience:\n","        print(\"early stopped. Current loss: \" + str(loss_epoch) + \"\\t min loss: \" + str(min_loss) + \"\\t epochs: \" + str(i))\n","        break\n","\n","  val = 1\n","  print(\"Starting Validation:\")\n","  for j in range(i+1):\n","      print((f\"Val Epoch {j+1}\"))\n","      loss_epoch, acc_epoch = train_one_epoch(model, val_dataloader, loss_fn, optimizer, device, val)\n","      val_losses.append(loss_epoch)\n","      val_accuracies.append(acc_epoch)\n","      print(\"----------------------------------------\")\n","\n","\n","  print(\"Training is done\")\n","  return train_losses, val_losses, train_accuracies, val_accuracies"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NPsKfKAaKlcB"},"source":["### Train Model"]},{"cell_type":"code","metadata":{"id":"-xHoHZ67nO3C"},"source":["CRNN = CRNN(nb_classes).to(device=device) #model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6Jq0D65l-ho","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ebc79c3b-4b64-4fda-d981-bc611165890c"},"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(CRNN.parameters(), lr=LEARNING_RATE, weight_decay=0.0005)\n","#optimizer = torch.optim.SGD(CRNN.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","\n","train_losses, val_losses, train_accuracies, val_accuracies = train(CRNN, train_dataloader, val_dataloader, loss_fn, optimizer, device, EPOCHS, patience_early_stopping, delta_early_stopping)\n","\n","torch.save(CRNN.state_dict(), \"/content/drive/MyDrive/team_project/GTZAN_x.pth\")\n","print(\"Model trained and stored at GTZAN_x.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training:\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 1.4163949489593506\n","Accuracy: 0.5\n","----------------------------------------\n","Epoch 2\n","Loss: 0.9197101593017578\n","Accuracy: 0.5\n","----------------------------------------\n","Epoch 3\n","Loss: 0.8208078145980835\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 4\n","Loss: 0.6375202536582947\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 5\n","Loss: 0.5577487945556641\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 6\n","Loss: 0.4775976836681366\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 7\n","Loss: 0.752646803855896\n","Accuracy: 0.5\n","----------------------------------------\n","Epoch 8\n","Loss: 1.1029573678970337\n","Accuracy: 0.5\n","----------------------------------------\n","Epoch 9\n","Loss: 0.22225157916545868\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 10\n","Loss: 0.3067842125892639\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 11\n","Loss: 0.38921865820884705\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 12\n","Loss: 0.07717126607894897\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 13\n","Loss: 0.09631133079528809\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 14\n","Loss: 0.03807936608791351\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 15\n","Loss: 0.08064237236976624\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 16\n","Loss: 0.09634506702423096\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 17\n","Loss: 0.016735753044486046\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 18\n","Loss: 0.16209328174591064\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 19\n","Loss: 0.040134407579898834\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 20\n","Loss: 0.015871291980147362\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 21\n","Loss: 0.033899471163749695\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 22\n","Loss: 0.22786998748779297\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 23\n","Loss: 0.0183943510055542\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 24\n","Loss: 0.9390990734100342\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 25\n","Loss: 0.054667405784130096\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 26\n","Loss: 0.035946015268564224\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 27\n","Loss: 0.03993585333228111\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 28\n","Loss: 0.05271495133638382\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 29\n","Loss: 0.039235033094882965\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 30\n","Loss: 0.059935830533504486\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 31\n","Loss: 0.40449148416519165\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 32\n","Loss: 0.12015648186206818\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 33\n","Loss: 0.1316264122724533\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 34\n","Loss: 0.009456781670451164\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 35\n","Loss: 0.04844692349433899\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 36\n","Loss: 0.04981329292058945\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 37\n","Loss: 0.010384615510702133\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 38\n","Loss: 0.010303450748324394\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 39\n","Loss: 0.0123928003013134\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 40\n","Loss: 0.3060091733932495\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 41\n","Loss: 0.038798149675130844\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 42\n","Loss: 0.33175545930862427\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 43\n","Loss: 0.023194488137960434\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 44\n","Loss: 0.1677619367837906\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 45\n","Loss: 0.01942037232220173\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 46\n","Loss: 0.008800645358860493\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 47\n","Loss: 0.013177003711462021\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 48\n","Loss: 0.47821730375289917\n","Accuracy: 0.75\n","----------------------------------------\n","Epoch 49\n","Loss: 0.030773555859923363\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 50\n","Loss: 0.03794129937887192\n","Accuracy: 1.0\n","----------------------------------------\n","Epoch 51\n"]}]},{"cell_type":"markdown","metadata":{"id":"X2fE1O_qWUz2"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"-4Ce2uDuOiDk"},"source":["'''CRNN = CRNN(10).to(device=device)\n","PATH = '/content/drive/MyDrive/team_project/GTZAN_x.pth'\n","CRNN.load_state_dict(torch.load(PATH))'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAqeaEk2tY7b"},"source":["from collections import defaultdict\n","from sklearn.utils import shuffle\n","\n","def predict(model, X, Y, S):\n","  \n","    model.eval()\n","    with torch.no_grad():\n","      \n","        prediction_l = []\n","        labels_l = []\n","\n","        songs = np.unique(S)\n","        \n","        for song in songs:\n","          print(song)\n","          X_song = X[S==song]\n","          Y_song = Y[S==song]\n","\n","          predictions = model(X_song)\n","          class_prediction = [torch.argmax(pred).item() for pred in predictions]\n","          print(class_prediction)\n","          actual_prediction = [torch.argmax(label).item() for label in Y_song]\n","\n","          p = defaultdict(int)\n","          t = defaultdict(int)\n","\n","          for i in class_prediction:\n","              p[i] += 1\n","          for i in actual_prediction:\n","              t[i] += 1\n","          \n","          pred_song = max(p.items(), key=lambda x: x[1])[0]\n","          actual_song = max(t.items(), key=lambda x: x[1])[0]\n","\n","          prediction_l.append(pred_song)\n","          labels_l.append(actual_song)\n","\n","    return prediction_l, labels_l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TE8FuMdSwEVI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632149188548,"user_tz":-120,"elapsed":2853,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"2bb1da07-7081-4166-e8c4-a0839e9c3f56"},"source":["preds, trues = predict(CRNN, X_test, Y_test, S_test_shuffled)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["blues00002\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","blues00019\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","blues00020\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","blues00021\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","blues00025\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","blues00037\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n","blues00043\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","blues00054\n","[0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","blues00065\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","blues00099\n","[0, 0, 0, 0, 1, 1, 0, 0, 1, 9, 0, 0, 0, 1, 5, 9, 6, 1, 0, 0]\n","classical00003\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00005\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00016\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00020\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00067\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00068\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00069\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00072\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00074\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","classical00082\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","country00011\n","[5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 7, 7]\n","country00013\n","[2, 9, 3, 9, 9, 7, 9, 3, 7, 2, 7, 9, 9, 2, 7, 2, 3, 2, 2, 7]\n","country00022\n","[2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","country00034\n","[2, 2, 8, 8, 8, 8, 2, 2, 2, 8, 2, 2, 8, 8, 2, 2, 8, 8, 2, 2]\n","country00042\n","[7, 9, 2, 2, 9, 2, 2, 9, 9, 7, 2, 7, 7, 7, 2, 9, 7, 7, 9, 2]\n","country00059\n","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2]\n","country00071\n","[2, 5, 1, 3, 2, 2, 5, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 0]\n","country00074\n","[2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","country00083\n","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","country00087\n","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2]\n","disco00006\n","[3, 3, 2, 3, 7, 3, 7, 2, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 7, 3]\n","disco00013\n","[7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","disco00030\n","[3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2]\n","disco00042\n","[3, 7, 7, 7, 9, 3, 7, 3, 9, 7, 7, 1, 3, 3, 8, 9, 1, 1, 7, 3]\n","disco00043\n","[3, 3, 7, 3, 3, 3, 7, 7, 3, 3, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3]\n","disco00045\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","disco00048\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","disco00058\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","disco00061\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","disco00095\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","hiphop00034\n","[4, 4, 7, 7, 4, 4, 7, 4, 4, 7, 7, 7, 7, 7, 7, 4, 4, 7, 4, 7]\n","hiphop00063\n","[4, 4, 7, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","hiphop00064\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","hiphop00068\n","[4, 4, 4, 7, 4, 7, 4, 7, 7, 4, 4, 7, 4, 4, 4, 4, 7, 4, 4, 4]\n","hiphop00069\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","hiphop00072\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","hiphop00081\n","[3, 3, 9, 3, 9, 9, 4, 9, 3, 3, 9, 9, 3, 4, 3, 3, 3, 3, 3, 3]\n","hiphop00084\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","hiphop00095\n","[6, 4, 6, 6, 6, 6, 6, 6, 4, 4, 4, 6, 6, 4, 4, 4, 4, 6, 6, 6]\n","hiphop00096\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","jazz00001\n","[1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1]\n","jazz00004\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","jazz00008\n","[5, 0, 0, 5, 0, 5, 0, 5, 0, 5, 5, 0, 0, 5, 5, 0, 0, 5, 5, 0]\n","jazz00029\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","jazz00032\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","jazz00034\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","jazz00040\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","jazz00052\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","jazz00056\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","jazz00077\n","[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n","metal00009\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","metal00026\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","metal00030\n","[9, 9, 6, 9, 6, 0, 9, 9, 6, 6, 9, 9, 9, 9, 9, 6, 9, 9, 0, 9]\n","metal00051\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","metal00067\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","metal00068\n","[6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6]\n","metal00078\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n","metal00083\n","[6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 0, 6, 6, 0, 0, 6, 6, 6, 6, 0]\n","metal00088\n","[6, 6, 6, 6, 6, 6, 4, 6, 6, 3, 6, 0, 9, 3, 3, 6, 6, 6, 6, 6]\n","metal00096\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6]\n","pop00013\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2]\n","pop00015\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","pop00031\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","pop00041\n","[2, 5, 8, 7, 2, 2, 7, 2, 7, 3, 2, 8, 8, 7, 9, 3, 5, 2, 2, 9]\n","pop00053\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","pop00058\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","pop00062\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","pop00076\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","pop00078\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","pop00091\n","[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n","reggae00007\n","[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n","reggae00026\n","[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n","reggae00040\n","[1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 5, 5, 1, 6, 0, 5, 0, 1, 5]\n","reggae00042\n","[8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n","reggae00055\n","[7, 3, 3, 7, 3, 3, 7, 3, 7, 7, 7, 3, 7, 7, 7, 3, 3, 7, 7, 3]\n","reggae00076\n","[8, 8, 8, 7, 7, 8, 4, 7, 7, 7, 7, 8, 8, 7, 4, 8, 8, 8, 8, 4]\n","reggae00078\n","[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n","reggae00088\n","[7, 7, 3, 7, 3, 7, 3, 7, 3, 7, 7, 7, 7, 7, 3, 7, 3, 7, 3, 7]\n","reggae00093\n","[7, 7, 8, 7, 7, 7, 8, 8, 7, 7, 7, 7, 7, 7, 8, 8, 7, 8, 8, 8]\n","reggae00096\n","[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n","rock00001\n","[9, 9, 5, 9, 0, 5, 2, 9, 0, 5, 9, 0, 9, 0, 9, 0, 9, 0, 0, 9]\n","rock00007\n","[2, 0, 2, 2, 0, 2, 9, 2, 2, 2, 9, 2, 2, 9, 9, 9, 0, 2, 2, 9]\n","rock00009\n","[2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 9, 2, 9, 9, 9, 9, 2, 9, 2]\n","rock00010\n","[9, 2, 2, 2, 2, 9, 2, 2, 9, 0, 2, 9, 2, 2, 9, 9, 9, 9, 2, 0]\n","rock00022\n","[9, 9, 9, 0, 0, 0, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 0, 9, 9, 9]\n","rock00024\n","[9, 9, 9, 0, 9, 9, 6, 0, 9, 1, 0, 0, 0, 9, 1, 9, 6, 6, 0, 9]\n","rock00047\n","[9, 6, 9, 6, 6, 9, 6, 7, 9, 7, 9, 9, 9, 4, 9, 9, 7, 7, 9, 9]\n","rock00053\n","[5, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 9, 7, 7, 7, 7, 7]\n","rock00076\n","[8, 2, 0, 9, 0, 2, 9, 2, 2, 2, 9, 9, 9, 2, 2, 2, 2, 9, 9, 2]\n","rock00090\n","[0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4]\n"]}]},{"cell_type":"markdown","metadata":{"id":"cjUcwpAQKzqQ"},"source":["##Performance Evaluation"]},{"cell_type":"code","metadata":{"id":"ldwS6acjwSXi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632149191641,"user_tz":-120,"elapsed":302,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"cb821afe-7051-43d5-ddf9-e20e25bfa6eb"},"source":["acc = accuracy_score(trues, preds)\n","f1 = f1_score(trues, preds, average='weighted')\n","cr = classification_report(trues, preds)\n","print(\"accuracy:\", acc)\n","print(\"f1 score:\", f1)\n","print(\"classification report:\")\n","print(cr)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy: 0.81\n","f1 score: 0.8096045930333855\n","classification report:\n","              precision    recall  f1-score   support\n","\n","           0       0.91      1.00      0.95        10\n","           1       0.83      1.00      0.91        10\n","           2       0.67      0.80      0.73        10\n","           3       0.89      0.80      0.84        10\n","           4       1.00      0.70      0.82        10\n","           5       0.90      0.90      0.90        10\n","           6       0.90      0.90      0.90        10\n","           7       0.53      0.90      0.67        10\n","           8       1.00      0.60      0.75        10\n","           9       0.83      0.50      0.62        10\n","\n","    accuracy                           0.81       100\n","   macro avg       0.85      0.81      0.81       100\n","weighted avg       0.85      0.81      0.81       100\n","\n"]}]},{"cell_type":"code","metadata":{"id":"nrePFOEAps7Z","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1632149201002,"user_tz":-120,"elapsed":643,"user":{"displayName":"Michele Dicataldo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14524552262225204300"}},"outputId":"04305380-d331-461c-acb2-347d45d71d43"},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Training Loss\")\n","plt.plot(train_losses,label=\"train\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"JfK__0c28uhs"},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Validation Loss\")\n","plt.plot(val_losses,label=\"validation\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j8Vt2rmrwejH"},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Training Accuracy\")\n","plt.plot(train_accuracies,label=\"train\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4kJ4RAbjegE"},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Validation Accuracy\")\n","plt.plot(val_accuracies,label=\"train\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vGq224dxhOGS"},"source":["### Deleting slicing folder"]},{"cell_type":"code","metadata":{"id":"sBRqYL3ep8s2"},"source":["shutil.rmtree('/content/drive/MyDrive/team_project/gtzan', ignore_errors=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5vR-H8EgDJZ"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"TrTEG0TPZ3iM"},"source":["def load_audio_file_segmented(songpath, segment):\n","\n","  sound = None\n","  song_tensor, _= ta.load(songpath)\n","  print(song_tensor.size()[1])\n","\n","  song_name = songpath.split('/')[-1].split('.')[0]\n","  root = '/content/drive/MyDrive/team_project/song_to_try/'\n","  os.makedirs(root+'slices')\n","  \n","\n","  if songpath.endswith('.mp3') or songpath.endswith('.MP3'):\n","      for w in range(0, (((song_tensor.size()[1]//44100)//segment)):\n","        t1 = segment*(w)*1000\n","        t2 = segment*(w+1)*1000\n","        newAudio = AudioSegment.from_mp3(songpath)\n","        sound = newAudio[t1:t2]\n","        sound.export(f'/content/drive/MyDrive/team_project/song_to_try/slices/{song_name+str(w)}.mp3', format=\"mp3\")\n","      newpath = root+'slices/'\n","\n","  elif songpath.endswith('.wav') or songpath.endswith('.WAV'):\n","      for w in range(0,((((song_tensor.size()[1]//22050)//segment) ):\n","        t1 = segment*(w)*1000\n","        t2 = segment*(w+1)*1000\n","        newAudio = AudioSegment.from_wav(songpath)\n","        sound = newAudio[t1:t2]\n","        sound.export(f'/content/drive/MyDrive/team_project/song_to_try/slices/{song_name+str(w)}.wav', format=\"wav\")\n","      newpath = root+'slices/' \n","    \n","  return newpath\n","\n","def get_data(songpath):\n","  hop_length = 512\n","  n_fft = 2048\n"," \n","  sound_tensor = []\n","\n","  for _,_,filenames in os.walk(songpath):\n","    for f in filenames:\n","      song = os.path.join(songpath,f'{f}')\n","      y, sr = ta.load(song)\n","      S = ta.transforms.MelSpectrogram(sample_rate=sr, hop_length=hop_length, n_fft=n_fft)(y) #(channel\\ num mels\\ time)\n","      sliced_sound = ta.transforms.AmplitudeToDB(stype='magnitude')(S)\n","      \n","      if sliced_sound.size()[0] > 1:\n","          sliced_sound = torch.unsqueeze(torch.mean(sliced_sound, dim=0), dim=0) # (2, num, time) = (1, num, time) + (1, num, time)\n","\n","      sound_tensor.append(sliced_sound)\n","  \n","  sound_tensor = torch.stack(sound_tensor).to(device)\n","  return sound_tensor\n","\n","def predict_song(songpath, segmentSize, model, n_classes, le):\n","  newpath = load_audio_file_segmented(songpath, segmentSize)\n","  sound_tensor = get_data(newpath)\n","  shutil.rmtree(newpath, ignore_errors=True)\n","  \n","  model.eval()\n","  with torch.no_grad():\n","    class_prediction = []\n","\n","    predictions = model(sound_tensor)\n","    class_prediction = [torch.argmax(pred).item() for pred in predictions]\n","    print(class_prediction)\n","\n","    p = defaultdict(int)\n","    for i in class_prediction:\n","      p[i] += 1\n","            \n","    pred_song = max(p.items(), key=lambda x: x[1])[0]\n","    c = Counter(class_prediction)\n","    outcomes = [(le.inverse_transform([i])[0], '%.3f'%(c[i] / len(class_prediction) * 100.0)) for i, count in c.most_common()] # [(blues, %), (jazz, %) ...]\n","    outcomes = outcomes[0:4]\n","    print(outcomes)\n","  \n","  return outcomes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2Yhsk12jUjg"},"source":["songpath = '/content/drive/MyDrive/team_project/song_to_try/715.wav'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVw2Z-0b0fIl"},"source":["preds = predict_song(songpath,3,CRNN,10,le)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DVdOkP9hiKCE"},"source":["## Multi-Classification visualization"]},{"cell_type":"code","metadata":{"id":"Le2D0CyO2N6B"},"source":["preds_cut = preds[0:4]\n","\n","others_sum = round(100-(preds[0][1]+preds[1][1]+preds[2][1]), 4)\n","others = ('others', others_sum)\n","preds_cut.pop()\n","preds_cut.append(others)\n","preds_cut"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fd0cX3_yqhRk"},"source":["import seaborn as sns\n","\n","plt.rcParams[\"figure.figsize\"] = [7, 4.5]\n","plt.rcParams[\"figure.autolayout\"] = True\n","ax = sns.barplot(x=[p[0] for p in preds_cut], y=[float(p[1]) for p in preds_cut], palette='PuBuGn_r')\n","patches = ax.patches\n","for i in range(len(patches)):\n","   x = patches[i].get_x() + patches[i].get_width()/2\n","   y = patches[i].get_height()+.01\n","   ax.annotate('{:.2f}%'.format(preds_cut[i][1]), (x, y), ha='center')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AszMsLooWpRJ"},"source":["### PLOTTING SPECTROGRAMS"]},{"cell_type":"code","metadata":{"id":"5q1E45jmpNA3"},"source":["def plot_specgram(waveform, sample_rate, title, xlim=None):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].specgram(waveform[c], Fs=sample_rate)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","  figure.suptitle(title)\n","  plt.show(block=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHB4eBiEKLZb"},"source":["song = '/content/drive/MyDrive/team_project/song_to_try/715.wav'\n","title = 'queen'\n","y, sr = ta.load(song)\n","if y.size()[0] > 1:\n","  y = torch.unsqueeze(torch.mean(y, dim=0), dim=0)\n","\n","print(f\"Shape of spectrogram: {y.size()} with sample rate {sr}\")\n","plot_specgram(y,sr,title)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXwhzjbAXOsT"},"source":[""],"execution_count":null,"outputs":[]}]}
